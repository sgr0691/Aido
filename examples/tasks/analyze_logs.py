#!/usr/bin/env python3
"""
Example Aido task: Log Analysis

Demonstrates a more realistic use case:
- Reading multiple input files
- Processing data
- Generating a structured report
- Writing multiple outputs
"""

import sys
import json
from pathlib import Path
from datetime import datetime
from collections import Counter


def analyze_log_file(file_path: Path) -> dict:
    """Analyze a single log file and extract metrics."""

    lines = file_path.read_text().splitlines()

    # Simple log level extraction (assumes format: [LEVEL] message)
    log_levels = Counter()
    errors = []

    for line in lines:
        if '[ERROR]' in line or '[FATAL]' in line:
            log_levels['ERROR'] += 1
            errors.append(line)
        elif '[WARN]' in line:
            log_levels['WARN'] += 1
        elif '[INFO]' in line:
            log_levels['INFO'] += 1
        elif '[DEBUG]' in line:
            log_levels['DEBUG'] += 1

    return {
        'file': file_path.name,
        'total_lines': len(lines),
        'log_levels': dict(log_levels),
        'errors': errors[:10],  # First 10 errors
    }


def main():
    print("=" * 50)
    print("Aido Task: Log Analysis")
    print("=" * 50)
    print()

    # Find input logs
    inputs_dir = Path("/inputs")
    if not inputs_dir.exists():
        inputs_dir = Path("./inputs")
        if not inputs_dir.exists():
            print("‚ùå No inputs directory found")
            print("Expected log files in /inputs or ./inputs")
            return 1

    log_files = list(inputs_dir.glob("**/*.log"))

    if not log_files:
        print("‚ö†Ô∏è  No .log files found in inputs")
        return 1

    print(f"üìã Found {len(log_files)} log file(s)")
    print()

    # Analyze each file
    results = []
    for log_file in log_files:
        print(f"Analyzing: {log_file.name}...")
        analysis = analyze_log_file(log_file)
        results.append(analysis)

    print()

    # Generate summary
    total_lines = sum(r['total_lines'] for r in results)
    total_errors = sum(r['log_levels'].get('ERROR', 0) for r in results)
    total_warnings = sum(r['log_levels'].get('WARN', 0) for r in results)

    print("Summary:")
    print(f"  Total files: {len(results)}")
    print(f"  Total lines: {total_lines}")
    print(f"  Total errors: {total_errors}")
    print(f"  Total warnings: {total_warnings}")
    print()

    # Write outputs
    outputs_dir = Path("/outputs")
    if not outputs_dir.exists():
        outputs_dir = Path("./outputs")
        outputs_dir.mkdir(exist_ok=True)

    # JSON report
    json_report = {
        'analyzed_at': datetime.now().isoformat(),
        'summary': {
            'files_analyzed': len(results),
            'total_lines': total_lines,
            'total_errors': total_errors,
            'total_warnings': total_warnings,
        },
        'files': results,
    }

    json_path = outputs_dir / "analysis.json"
    json_path.write_text(json.dumps(json_report, indent=2))
    print(f"‚úì JSON report: {json_path}")

    # Markdown report
    markdown = f"""# Log Analysis Report

**Generated:** {datetime.now().isoformat()}

## Summary

- **Files Analyzed:** {len(results)}
- **Total Lines:** {total_lines:,}
- **Total Errors:** {total_errors}
- **Total Warnings:** {total_warnings}

## Files

"""

    for result in results:
        markdown += f"\n### {result['file']}\n\n"
        markdown += f"- Lines: {result['total_lines']:,}\n"
        markdown += f"- Log Levels: {result['log_levels']}\n"

        if result['errors']:
            markdown += f"\n**First {len(result['errors'])} errors:**\n\n"
            for error in result['errors']:
                markdown += f"```\n{error}\n```\n\n"

    markdown += f"\n---\n\n*Generated by Aido*\n"

    md_path = outputs_dir / "report.md"
    md_path.write_text(markdown)
    print(f"‚úì Markdown report: {md_path}")

    print()
    print("=" * 50)
    print("Analysis complete!")
    print("=" * 50)

    return 0


if __name__ == "__main__":
    sys.exit(main())
